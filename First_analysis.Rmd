---
title: "First Analysis"
author: "Taylan Kabbani"
date: "January 19, 2021"
output: pdf_document
---
# Required Packages and data import
```{r, warning = FALSE, message = FALSE}
library(readxl)
library(tidyverse)
library(ggfortify)
library(ggplot2)
library(tsbox)
library(imputeTS)
library(cowplot)
library(forecast)

SpotifyData <- read_excel("Data/SpotifyData.xlsx")
```


```{r, warning = FALSE, message = FALSE}
# Extracting specific song streams and return it as ts object
FindSong <- function(SongName, Artist){
  song_strams <- as.data.frame(SpotifyData %>% filter(song == SongName & Artist == Artist)
                               %>% select(Date,Streams))
  # ts_ts will convert df to time series
  song_strams <- ts_ts(song_strams)
  song_strams
}
```

# SOng2
## Preliminary (exploratory) analysis.
```{r, warning = FALSE, message = FALSE}
song2 <- FindSong('Seni Dert Etmeler', 'Madrigal')

song2_plt1 <- autoplot(song2) +
  ggtitle('Song: Seni Dert Etmeler') +
  xlab("Weeks") +
  ylab("# Streams")

# Imputation by Interpolation method is used to fill missing values. This method is appropriate for time series with strong trend. [ref1]

ggplot_na_imputations(song2, na_interpolation(song2))

song2 <- na_interpolation(song2)
song2
```

```{r}
# From the ACF plot we conclude that the data is non stationary having a strong trend and cyclical components and no seasonality
ggAcf(song2)
```

```{r}
# The time series we are dealing with that have been collected at regular intervals (weekly) that are less than the one year (42 weeks), therefore normal decomposition method will not be useful. 
#It is possible to use a linear regression model to decompose a time series into trend and seasonal components, and then some smoothness assumptions on the seasonal component allow a decomposition with fewer than two full years of data. 

# Approximating the seasonal pattern using Fourier terms with a few parameters.
decompose_song2 <- tslm(song2 ~ trend + fourier(song2, 1))

# Trend component as moving average function
trend <- coef(decompose_song2)['(Intercept)'] +coef(decompose_song2)['trend']*seq_along(song2)

e <- residuals(decompose_song2)

# Additive model is used to decompose the time series data
seasonality <- song2 - trend - e

components <- cbind(
  data = song2,
  trend = trend,
  seasonal = seasonality,
  residuals =e
  )

autoplot(components,facet=TRUE)

```

```{r}
# Remove the seasonality component from the data (Seasonly adjusted) as the purpose of our forecast is next week only and not interested in the seasonlay component.

adjust_song2 <- song2 - seasonality
autoplot(song2, series="Data") +
  autolayer(adjust_song2, series="Seasonally adjusted")
```

# Data partitioning: leaving the last observation as test data, as we are only interested in forcasting only the next data point (short-term forcasting)
```{r}

train <- subset(song2, end = length(song2)-1)

test <- subset(song2, start= length(song2))
test
```


## Starting with Holt's linear trend method, as we anticpate a clear trend in the data this method is a good point to start with, setting to start the initial solution by taking the average values of the first few observations. Holt's Method makes predictions for data with a trend using two smoothing parameters, alpha and beta which correspond to the level and trend components, respectively. Holt's method parameteres (alpha and beta) are beeing selected using grid search.

### manually identify the optimal model parameters using grid search, using only train data
```{r}
Optimal_param <- function(data, show=FALSE){
  train <- subset(data, end = length(data)-1)
  validate <- subset(data, start= length(data))
    # loop through a series of betas and alphas
  param <- seq(.0001, 1, by = .001)
  beta <- seq(.0001, 1, by = .001)
  RMSE_beta <- NA
  RMSE_alpha <- NA

  for(i in seq_along(param)) {
    fit_alpha <- holt(train, alpha = param[i], h = 1)
    RMSE_alpha[i] <- accuracy(fit_alpha, validate)[2,2]
    fit_beta <- holt(train, beta = param[i], h = 1)
    RMSE_beta[i] <- accuracy(fit_beta, validate)[2,2]
  }
  
  # convert to a data frame and idenitify min alpha and beta value
  df <- data_frame(param, RMSE_alpha, RMSE_beta)
  alpha.opt <- filter(df, RMSE_alpha == min(RMSE_alpha)) %>% select(param,RMSE_alpha)
  beta.opt <- filter(df, RMSE_beta == min(RMSE_beta)) %>% select(param,RMSE_beta)
  
  # plot RMSE vs. alpha
  if (show==TRUE) {
      plot <- ggplot(df, aes(param,RMSE_alpha)) +
        geom_line(color='blue')+
        geom_line(aes(param,RMSE_beta),color = 'red')+
        geom_point(data = alpha.opt, aes(param, RMSE_alpha), size = 3, color = "blue")+
        geom_point(data = beta.opt, aes(param, RMSE_beta), size = 3, color = "Red")
        
      
      return(list(plot,alpha.opt,beta.opt))} else{return(list(alpha.opt,beta.opt))}


  
}
param <- Optimal_param(song2,show=FALSE)
```



```{r}
#Holt's linear trend method
Alpha <- as.numeric(param[[1]][1])
Beta<- as.numeric(param[[2]][1])
fit <- holt(train, alpha = Alpha, beta = Beta, h =1,initial = 'optimal')
# Naive forecast for seasonality

# model parameters
Alpha = fit$model$fit$par[1]
Beta = fit$model$fit$par[2]

# Residual diagnostics
e_check <- checkresiduals(fit)

#The model passes residuals check:
#1. The residuals are uncorrelated(There are a few significant spikes in the ACF)
#2. The residuals have zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model fails the Ljung-Box test. The model can still be used for forecasting. 

# Check model accuracy: According to our MAPE we have about a 5.33 error rate and test-RMSE = 78250.48
round(accuracy(fit, test),2)

# One-step prediction intervals


autoplot(fit) +
  autolayer(fit, series="Holt's method", PI=FALSE) +
  autolayer(song2, series="Data", PI=FALSE) +
  ggtitle("Forecasts from Holt's method") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```


```{r, warning = FALSE, message = FALSE}
fit$model


```



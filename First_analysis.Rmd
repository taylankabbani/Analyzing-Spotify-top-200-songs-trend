---
title: "First Analysis"
author: "Taylan Kabbani"
date: "January 19, 2021"
output: pdf_document
---
# Required Packages and data import
```{r, warning = FALSE, message = FALSE}
library(readxl)
library(tidyverse)
library(ggfortify)
library(ggplot2)
library(tsbox)
library(imputeTS)
library(cowplot)
library(forecast)

SpotifyData <- read_excel("Data/SpotifyData_full.xlsx")
top100 <- read_excel('Data/top100.xlsx')
```

```{r, warning = FALSE, message = FALSE}
# Extracting specific song streams and return it as ts object
FindSong <- function(SongName, ArtistName){
  song_streams <- as.data.frame(SpotifyData %>% filter(song == SongName & Artist == ArtistName)
                               %>% select(Date,Streams))
  # ts_ts will convert df to time series
  song_streams <- ts_ts(song_streams)
  song_streams
}
```


# Analysis of very short time-series (< 10)

```{r}
vShort_songs <- top100 %>% filter(counts <= 10)
dim(vShort_songs)
head(vShort_songs)
```

# Analysis of short time-series (> 10 but < 54)
```{r}
Short_songs <- top100 %>% filter(counts > 10 & counts <= 54)
head(Short_songs)
```
# SOng2
## Preliminary (exploratory) analysis.
```{r, warning = FALSE, message = FALSE}
song2 <- FindSong("Bil Diye Söylüyorum", "Sibel Can")


# Imputation by Interpolation method is used to fill missing values. This method is appropriate for time series with strong trend. [ref1]

#ggplot_na_imputations(song2, na_interpolation(song2))

#song2 <- na_interpolation(song2)
song2
```

```{r}
# From the ACF plot, we conclude that the data is nonstationary having a strong trend and cyclical components and no seasonality.
ggAcf(song2)
```

```{r}
# The time series we are dealing with have been collected at regular intervals (weekly) for less than one year (42 weeks), therefore the normal decomposition method will not be useful. 
#It is possible to use a linear regression model to decompose a time series into the trend and seasonal components, and then some smoothness assumptions on the seasonal component allow a decomposition with fewer than two full years of data. 

# Approximating the seasonal pattern using Fourier terms with a few parameters.
decompose_song2 <- tslm(song2 ~ trend + fourier(song2, 1))

# Trend component as moving average function
trend <- coef(decompose_song2)['(Intercept)'] +coef(decompose_song2)['trend']*seq_along(song2)

e <- residuals(decompose_song2)

# Additive model is used to decompose the time series data
seasonality <- song2 - trend - e

components <- cbind(
  data = song2,
  trend = trend,
  seasonal = seasonality,
  residuals =e
  )

autoplot(components,facet=TRUE)

```


## Data partitioning: leaving the last observation as test data, as we are only interested in forcasting only the next data point (short-term forcasting)
```{r}

train <- subset(song2, end = length(song2)-1)

test <- subset(song2, start= length(song2))

```

# Method 1 : Holt's linear trend method

## Starting with Holt's linear trend method, as we anticipate a clear trend in the data this method is a good point to start with, setting to start the initial solution by taking the average values of the first few observations. Holt's Method makes predictions for data with a trend using two smoothing parameters, alpha, and beta which correspond to the level and trend components, respectively. Holt's method parameters (alpha and beta) are being selected using grid search.

### manually identify the optimal model parameters using grid search, using only train data
```{r}
Optimal_param <- function(data, show=FALSE){
  train <- subset(data, end = length(data)-1)
  validate <- subset(data, start= length(data))
    # loop through a series of betas and alphas
  param <- seq(.0001, 1, by = .001)
  RMSE_beta <- NA
  RMSE_alpha <- NA

  for(i in seq_along(param)) {
    fit_alpha <- holt(train, alpha = param[i], h = 1)
    RMSE_alpha[i] <- accuracy(fit_alpha, validate)[2,2]
    fit_beta <- holt(train, beta = param[i], h = 1)
    RMSE_beta[i] <- accuracy(fit_beta, validate)[2,2]
  }
  
  # convert to a data frame and idenitify min alpha and beta value
  df <- data_frame(param, RMSE_alpha, RMSE_beta)
  alpha.opt <- filter(df, RMSE_alpha == min(RMSE_alpha)) %>% select(param,RMSE_alpha)
  beta.opt <- filter(df, RMSE_beta == min(RMSE_beta)) %>% select(param,RMSE_beta)
  
  # plot RMSE vs. alpha
  if (show==TRUE) {
      plot <- ggplot(df, aes(param,RMSE_alpha)) +
        geom_line(color='blue')+
        geom_line(aes(param,RMSE_beta),color = 'red')+
        geom_point(data = alpha.opt, aes(param, RMSE_alpha), size = 3, color = "blue")+
        geom_point(data = beta.opt, aes(param, RMSE_beta), size = 3, color = "Red")
        
      
      return(list(plot,alpha.opt,beta.opt))} else{return(list(alpha.opt,beta.opt))}


  
}
param <- Optimal_param(song2,show=FALSE)
```



```{r}
#Holt's linear trend method
Alpha <- as.numeric(param[[1]][1])
Beta<- as.numeric(param[[2]][1])
fit <- holt(train, alpha=Alpha ,damped = FALSE, h =1,initial = 'optimal')


# Residual diagnostics
e_check <- checkresiduals(fit)

#The model passes residuals check:
#1. The residuals are uncorrelated(There are a few significant spikes in the ACF)
#2. The residuals have zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model fails the Ljung-Box test. The model can still be used for forecasting. 

# Check model accuracy: According to our MAPE we have about a 5.33 error rate and test-RMSE = 78250
round(accuracy(fit, test),2)

# One-step prediction intervals
print(paste('80% prediction intervals: ', round(fit$upper[1],3),'-' , round(fit$lower[1],3)))


autoplot(fit) +
  autolayer(fitted(fit), series="Holt's method") +
  autolayer(song2, series="Data") +
  ggtitle("Forecasts from Holt's method") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```
## It seems that the forcasting method is over-forecasting the trend thus we shall try to dampe the trend.
```{r}
#Holt's linear damped trend method
Alpha <- as.numeric(param[[1]][1])
Beta<- as.numeric(param[[2]][1])
fit <- holt(train,alpha = Alpha,damped = TRUE,  h =1,initial = 'optimal')


# Residual diagnostics
e_check <- checkresiduals(fit)

#The model passes residuals check:
#1. The residuals are uncorrelated(There are a few significant spikes in the ACF)
#2. The residuals have zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model fails the Ljung-Box test. The model can still be used for forecasting. 

# Check model accuracy: According to our MAPE we have about a 1.66 error rate and test-RMSE = 24409
round(accuracy(fit, test),2)

# One-step prediction intervals
print(paste('80% prediction intervals: ', round(fit$upper[1],3),'-' , round(fit$lower[1],3)))


autoplot(fit) +
  autolayer(fitted(fit), series="Holt's method with damped trend", PI=FALSE) +
  autolayer(song2, series="Data", PI=FALSE) +
  ggtitle("Forecasts from Holt's method") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```


## By letting ETS automaticly selecting the model, we get ETS(M,A,N), Holt's linear method with multiplicative errors. This model is assumed "optimal" because it minimizes RMSE, AIC, and BIC on the training data set, but does not necessarily minimize prediction errors on the test set.
```{r, warning = FALSE, message = FALSE}
fit2 <- ets(train, model='ZZZ')
fit2



# Residual diagnostics
e_check <- checkresiduals(fit)

#The model passes residuals check:
#1. The residuals are uncorrelated(There are a few significant spikes in the ACF)
#2. The residuals have zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model fails the Ljung-Box test. The model can still be used for forecasting. 

# one-step ahead forecast
pred <- forecast(fit2, h=1)


# Check model accuracy: According to our MAPE we have about a 15.19 error rate and test-RMSE = 222939
round(accuracy(forecast(fit2, h=1), test),2)

# One-step prediction intervals
print(paste('80% prediction intervals: ', round(pred$upper[1],3),'-' , round(pred$lower[1],3)))

autoplot(pred) +
  autolayer(fitted(fit2), series="ETS(M,A,N)", PI=FALSE) +
  autolayer(song2, series="Data", PI=FALSE) +
  ggtitle("Forecasts from ETS(M,A,N)") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```
### From the above our first method of forecast is Holt method with damped trend and Alpha = 0.511, Beta = 0.0981



# Method 2 :  Non-seasonal ARIMA models
## Because we have a large number of time-series to work with, auto.arime() will be used to select the model rather than manually investigate the ACF and PACF to choose Arima's coefficient, to force auto.arime() to investigate larger set of models by using the arguments stepwise=FALSE and approximation=FALSE. We also use the argument seasonal=FALSE to prevent it searching for seasonal ARIMA models
```{r}

# Use auto.arima to select a model.
(fit3 <- auto.arima(train,seasonal = FALSE, approximation = FALSE, stepwise = FALSE))

# Residual diagnostics
e_check <- checkresiduals(fit3)

#The model passes residuals check:
#1. The residuals are uncorrelated
#2. The residuals have zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model successfully passed the Ljung-Box test. Residuals are weight noise

# one-step ahead forecast
pred <- forecast(fit3, h=1)

# Check model accuracy: According to our MAPE we have about a 9.40 error rate and test-RMSE = 137948.0
round(accuracy(pred, test),2)

# One-step prediction intervals
print(paste('80% prediction intervals: ', round(pred$upper[1],3),'-' , round(pred$lower[1],3)))

autoplot(pred) +
  autolayer(fitted(fit3), series="ARIMA(p,d,q)", PI=FALSE) +
  autolayer(song2, series="Data", PI=FALSE) +
  ggtitle("Forecasts from ARIMA(p,d,q)") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```

# Method 3: Exponential regression using trend as predictor
```{r}
fit.exp <- tslm(train ~ trend, lambda = 0,h=1)
fit.exp$method

# Residual diagnostics
# checkresiduals(fit.exp)
#The model passes residuals check:
#1. The residuals are uncorrelated(There are a few significant spikes in the ACF)
#2. The residuals have almost zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model fails the Ljung-Box test. The model can still be used for forecasting. 

# one-step ahead forecast
fcasts.exp <- forecast(fit.exp, h = 1)

# Check model accuracy: 
round(accuracy(fcasts.exp, test),2)

# One-step prediction intervals
print(paste('80% prediction intervals: ', round(fcasts.exp$upper[1],3),'-' , round(fcasts.exp$lower[1],3)))



autoplot(fcasts.exp) +
  autolayer(fitted(fit.exp), series="Exponential", PI=FALSE) +
  autolayer(song2, series="Data", PI=FALSE) +
  ggtitle("Forecasts from Exponential") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```

# Method 4: Dynamic regression
```{r}
# useful predictors:
#1. The rank of the song in the top 200s
FindRank<- function(SongName, Artist){
  song_Rank <- as.data.frame(SpotifyData %>% filter(song == SongName & Artist == Artist) %>% select(Date,Rank))}

#Converting to time-series and impute missing values
song2_Rank <- na_interpolation(ts_ts(FindRank("Bil Diye Söylüyorum", "Sibel Can")))

# Frcasting the Rank 
train_pred <- subset(song2_Rank, end = length(song2_Rank)-1)

test_pred <- subset(song2_Rank, start= length(song2_Rank))

test_pred
```

# We can clearly see that there is a non-linear relationship between the rank and the number of streams
```{r}
song2_reg <- cbind('streams'= song2, 'rank'=song2_Rank)
song2_reg %>%
  as.data.frame() %>%
  ggplot(aes(x=streams, y=rank)) +
    ylab("Weekly rank in the top 200") +
    xlab("Streams per week") +
    geom_point() +
    geom_smooth(method="", se=FALSE)
```

```{r}
#Dynamic Regression method
fit.xreg <- auto.arima(train, xreg = train_pred)


# Residual diagnostics
e_check <- checkresiduals(fit.xreg)

#The model passes residuals check:
#1. The residuals are uncorrelated(There are a few significant spikes in the ACF)
#2. The residuals have zero mean.
#3. The variation of the residuals stays much the same across the historical data, apart from the one outlier.
#4. Residuals may not be normal - the right tail seems a little too long.
#5. The large positive residual is a result of the unexpected jump.
#6. The model fails the Ljung-Box test. The model can still be used for forecasting. 


# one-step ahead forecast
fcasts.xreg <- forecast(fit.xreg,xreg = f_rank_train, h = 1)

# Check model accuracy: According to our MAPE we have about a 5.33 error rate and test-RMSE = 78250
round(accuracy(fcasts.xreg, test),2)
# One-step prediction intervals
print(paste('80% prediction intervals: ', round(fcasts.xreg$upper[1],3),'-' , round(fcasts.xreg$lower[1],3)))


autoplot(fcasts.xreg) +
  autolayer(fitted(fit.xreg), series="xreg", PI=FALSE) +
  autolayer(song2, series="Data", PI=FALSE) +
  ggtitle("Forecasts from xreg") + xlab("Weeks") +
  ylab("Number of streams") +
  guides(colour=guide_legend(title="Forecast"))
```




